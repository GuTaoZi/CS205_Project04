bool matmul_sse(Matrix *src1, Matrix *src2, Matrix *dst)
{
    if (!safe_check(src1, src2, dst))
    {
        return false;
    }
    size_t n = src1->row;

    float *f1 = (float*)memalign(32,sizeof(float)*n*n);
    float *f2 = (float*)memalign(32,sizeof(float)*n*n);
    float *f3 = (float*)memalign(32,sizeof(float)*n*n);
    printf("%d\n",sizeof(float)*n*n);
    for(size_t i=0;i<n*n;i++)
    {
        f1[i]=src1->data[i];
        printf("666\n");
        f2[i]=src2->data[i];
    }
    printf("6\n");
    #pragma omp parallel
    for (size_t i = 0; i < n; i += 8)
    {
        for (size_t j = 0; j < n; j += 8)
        {
            __m256 ymm0, ymm1, ymm2, ymm3, ymm4, ymm5, ymm6, ymm7,
                ymm8, ymm9, ymm10, ymm11, ymm12, ymm13, ymm14, ymm15;

            __m256 ymm16 = _mm256_setzero_ps();
            __m256 ymm17 = _mm256_setzero_ps();
            __m256 ymm18 = _mm256_setzero_ps();
            __m256 ymm19 = _mm256_setzero_ps();
            __m256 ymm20 = _mm256_setzero_ps();
            __m256 ymm21 = _mm256_setzero_ps();
            __m256 ymm22 = _mm256_setzero_ps();
            __m256 ymm23 = _mm256_setzero_ps();

            for (size_t k = 0; k < n; k += 8)
            {
#define AVX_PFDIST 8
                _mm_prefetch(f2 + (k + AVX_PFDIST + 0) * n + j, _MM_HINT_T1);
                _mm_prefetch(f2 + (k + AVX_PFDIST + 1) * n + j, _MM_HINT_T1);
                _mm_prefetch(f2 + (k + AVX_PFDIST + 2) * n + j, _MM_HINT_T1);
                _mm_prefetch(f2 + (k + AVX_PFDIST + 3) * n + j, _MM_HINT_T1);
                _mm_prefetch(f2 + (k + AVX_PFDIST + 4) * n + j, _MM_HINT_T1);
                _mm_prefetch(f2 + (k + AVX_PFDIST + 5) * n + j, _MM_HINT_T1);
                _mm_prefetch(f2 + (k + AVX_PFDIST + 6) * n + j, _MM_HINT_T1);
                _mm_prefetch(f2 + (k + AVX_PFDIST + 7) * n + j, _MM_HINT_T1);

                // load eight rows from source 2
                ymm0 = _mm256_load_ps((__m256 *)(f2 + (k + 0) * n + j));
                ymm1 = _mm256_load_ps((__m256 *)(f2 + (k + 1) * n + j));
                ymm2 = _mm256_load_ps((__m256 *)(f2 + (k + 2) * n + j));
                ymm3 = _mm256_load_ps((__m256 *)(f2 + (k + 3) * n + j));
                ymm4 = _mm256_load_ps((__m256 *)(f2 + (k + 4) * n + j));
                ymm5 = _mm256_load_ps((__m256 *)(f2 + (k + 5) * n + j));
                ymm6 = _mm256_load_ps((__m256 *)(f2 + (k + 6) * n + j));
                ymm7 = _mm256_load_ps((__m256 *)(f2 + (k + 7) * n + j));

                // broadcast each elements from source 1
                ymm8 = _mm256_set1_ps(f1[(i + 0) * n + k + 0]);
                ymm9 = _mm256_set1_ps(f1[(i + 0) * n + k + 1]);
                ymm10 = _mm256_set1_ps(f1[(i + 0) * n + k + 2]);
                ymm11 = _mm256_set1_ps(f1[(i + 0) * n + k + 3]);
                ymm12 = _mm256_set1_ps(f1[(i + 0) * n + k + 4]);
                ymm13 = _mm256_set1_ps(f1[(i + 0) * n + k + 5]);
                ymm14 = _mm256_set1_ps(f1[(i + 0) * n + k + 6]);
                ymm15 = _mm256_set1_ps(f1[(i + 0) * n + k + 7]);

                // multiply
                ymm8 = _mm256_mul_ps(ymm8, ymm0); // row 1, 2
                ymm9 = _mm256_mul_ps(ymm9, ymm1);
                ymm8 = _mm256_add_ps(ymm8, ymm9);

                ymm10 = _mm256_mul_ps(ymm10, ymm2); // row 3, 4
                ymm11 = _mm256_mul_ps(ymm11, ymm3);
                ymm10 = _mm256_add_ps(ymm10, ymm11);

                ymm12 = _mm256_mul_ps(ymm12, ymm4); // row 5, 6
                ymm13 = _mm256_mul_ps(ymm13, ymm5);
                ymm12 = _mm256_add_ps(ymm12, ymm13);

                ymm14 = _mm256_mul_ps(ymm14, ymm6); // row 7, 8
                ymm15 = _mm256_mul_ps(ymm15, ymm7);
                ymm14 = _mm256_add_ps(ymm14, ymm15);

                ymm8 = _mm256_add_ps(ymm8, ymm10); // sum
                ymm12 = _mm256_add_ps(ymm12, ymm14);
                ymm8 = _mm256_add_ps(ymm8, ymm12);

                // save current result
                ymm16 = _mm256_add_ps(ymm16, ymm8);

                // ---------------------------------------------------------- //
                // broadcast each elements from source 1
                ymm8 = _mm256_set1_ps(f1[(i + 1) * n + k + 0]);
                ymm9 = _mm256_set1_ps(f1[(i + 1) * n + k + 1]);
                ymm10 = _mm256_set1_ps(f1[(i + 1) * n + k + 2]);
                ymm11 = _mm256_set1_ps(f1[(i + 1) * n + k + 3]);
                ymm12 = _mm256_set1_ps(f1[(i + 1) * n + k + 4]);
                ymm13 = _mm256_set1_ps(f1[(i + 1) * n + k + 5]);
                ymm14 = _mm256_set1_ps(f1[(i + 1) * n + k + 6]);
                ymm15 = _mm256_set1_ps(f1[(i + 1) * n + k + 7]);

                // multiply
                ymm8 = _mm256_mul_ps(ymm8, ymm0); // row 1, 2
                ymm9 = _mm256_mul_ps(ymm9, ymm1);
                ymm8 = _mm256_add_ps(ymm8, ymm9);

                ymm10 = _mm256_mul_ps(ymm10, ymm2); // row 3, 4
                ymm11 = _mm256_mul_ps(ymm11, ymm3);
                ymm10 = _mm256_add_ps(ymm10, ymm11);

                ymm12 = _mm256_mul_ps(ymm12, ymm4); // row 5, 6
                ymm13 = _mm256_mul_ps(ymm13, ymm5);
                ymm12 = _mm256_add_ps(ymm12, ymm13);

                ymm14 = _mm256_mul_ps(ymm14, ymm6); // row 7, 8
                ymm15 = _mm256_mul_ps(ymm15, ymm7);
                ymm14 = _mm256_add_ps(ymm14, ymm15);

                ymm8 = _mm256_add_ps(ymm8, ymm10); // sum
                ymm12 = _mm256_add_ps(ymm12, ymm14);
                ymm8 = _mm256_add_ps(ymm8, ymm12);

                // save current result
                ymm17 = _mm256_add_ps(ymm17, ymm8);

                // ---------------------------------------------------------- //
                // broadcast each elements from source 1
                ymm8 = _mm256_set1_ps(f1[(i + 2) * n + k + 0]);
                ymm9 = _mm256_set1_ps(f1[(i + 2) * n + k + 1]);
                ymm10 = _mm256_set1_ps(f1[(i + 2) * n + k + 2]);
                ymm11 = _mm256_set1_ps(f1[(i + 2) * n + k + 3]);
                ymm12 = _mm256_set1_ps(f1[(i + 2) * n + k + 4]);
                ymm13 = _mm256_set1_ps(f1[(i + 2) * n + k + 5]);
                ymm14 = _mm256_set1_ps(f1[(i + 2) * n + k + 6]);
                ymm15 = _mm256_set1_ps(f1[(i + 2) * n + k + 7]);

                // multiply
                ymm8 = _mm256_mul_ps(ymm8, ymm0); // row 1, 2
                ymm9 = _mm256_mul_ps(ymm9, ymm1);
                ymm8 = _mm256_add_ps(ymm8, ymm9);

                ymm10 = _mm256_mul_ps(ymm10, ymm2); // row 3, 4
                ymm11 = _mm256_mul_ps(ymm11, ymm3);
                ymm10 = _mm256_add_ps(ymm10, ymm11);

                ymm12 = _mm256_mul_ps(ymm12, ymm4); // row 5, 6
                ymm13 = _mm256_mul_ps(ymm13, ymm5);
                ymm12 = _mm256_add_ps(ymm12, ymm13);

                ymm14 = _mm256_mul_ps(ymm14, ymm6); // row 7, 8
                ymm15 = _mm256_mul_ps(ymm15, ymm7);
                ymm14 = _mm256_add_ps(ymm14, ymm15);

                ymm8 = _mm256_add_ps(ymm8, ymm10); // sum
                ymm12 = _mm256_add_ps(ymm12, ymm14);
                ymm8 = _mm256_add_ps(ymm8, ymm12);

                // save current result
                ymm18 = _mm256_add_ps(ymm18, ymm8);

                // ---------------------------------------------------------- //
                // broadcast each elements from source 1
                ymm8 = _mm256_set1_ps(f1[(i + 3) * n + k + 0]);
                ymm9 = _mm256_set1_ps(f1[(i + 3) * n + k + 1]);
                ymm10 = _mm256_set1_ps(f1[(i + 3) * n + k + 2]);
                ymm11 = _mm256_set1_ps(f1[(i + 3) * n + k + 3]);
                ymm12 = _mm256_set1_ps(f1[(i + 3) * n + k + 4]);
                ymm13 = _mm256_set1_ps(f1[(i + 3) * n + k + 5]);
                ymm14 = _mm256_set1_ps(f1[(i + 3) * n + k + 6]);
                ymm15 = _mm256_set1_ps(f1[(i + 3) * n + k + 7]);

                // multiply
                ymm8 = _mm256_mul_ps(ymm8, ymm0); // row 1, 2
                ymm9 = _mm256_mul_ps(ymm9, ymm1);
                ymm8 = _mm256_add_ps(ymm8, ymm9);

                ymm10 = _mm256_mul_ps(ymm10, ymm2); // row 3, 4
                ymm11 = _mm256_mul_ps(ymm11, ymm3);
                ymm10 = _mm256_add_ps(ymm10, ymm11);

                ymm12 = _mm256_mul_ps(ymm12, ymm4); // row 5, 6
                ymm13 = _mm256_mul_ps(ymm13, ymm5);
                ymm12 = _mm256_add_ps(ymm12, ymm13);

                ymm14 = _mm256_mul_ps(ymm14, ymm6); // row 7, 8
                ymm15 = _mm256_mul_ps(ymm15, ymm7);
                ymm14 = _mm256_add_ps(ymm14, ymm15);

                ymm8 = _mm256_add_ps(ymm8, ymm10); // sum
                ymm12 = _mm256_add_ps(ymm12, ymm14);
                ymm8 = _mm256_add_ps(ymm8, ymm12);

                // save current result
                ymm19 = _mm256_add_ps(ymm19, ymm8);

                // ---------------------------------------------------------- //
                // broadcast each elements from source 1
                ymm8 = _mm256_set1_ps(f1[(i + 4) * n + k + 0]);
                ymm9 = _mm256_set1_ps(f1[(i + 4) * n + k + 1]);
                ymm10 = _mm256_set1_ps(f1[(i + 4) * n + k + 2]);
                ymm11 = _mm256_set1_ps(f1[(i + 4) * n + k + 3]);
                ymm12 = _mm256_set1_ps(f1[(i + 4) * n + k + 4]);
                ymm13 = _mm256_set1_ps(f1[(i + 4) * n + k + 5]);
                ymm14 = _mm256_set1_ps(f1[(i + 4) * n + k + 6]);
                ymm15 = _mm256_set1_ps(f1[(i + 4) * n + k + 7]);

                // multiply
                ymm8 = _mm256_mul_ps(ymm8, ymm0); // row 1, 2
                ymm9 = _mm256_mul_ps(ymm9, ymm1);
                ymm8 = _mm256_add_ps(ymm8, ymm9);

                ymm10 = _mm256_mul_ps(ymm10, ymm2); // row 3, 4
                ymm11 = _mm256_mul_ps(ymm11, ymm3);
                ymm10 = _mm256_add_ps(ymm10, ymm11);

                ymm12 = _mm256_mul_ps(ymm12, ymm4); // row 5, 6
                ymm13 = _mm256_mul_ps(ymm13, ymm5);
                ymm12 = _mm256_add_ps(ymm12, ymm13);

                ymm14 = _mm256_mul_ps(ymm14, ymm6); // row 7, 8
                ymm15 = _mm256_mul_ps(ymm15, ymm7);
                ymm14 = _mm256_add_ps(ymm14, ymm15);

                ymm8 = _mm256_add_ps(ymm8, ymm10); // sum
                ymm12 = _mm256_add_ps(ymm12, ymm14);
                ymm8 = _mm256_add_ps(ymm8, ymm12);

                // save current result
                ymm20 = _mm256_add_ps(ymm20, ymm8);

                // ---------------------------------------------------------- //
                // broadcast each elements from source 1
                ymm8 = _mm256_set1_ps(f1[(i + 5) * n + k + 0]);
                ymm9 = _mm256_set1_ps(f1[(i + 5) * n + k + 1]);
                ymm10 = _mm256_set1_ps(f1[(i + 5) * n + k + 2]);
                ymm11 = _mm256_set1_ps(f1[(i + 5) * n + k + 3]);
                ymm12 = _mm256_set1_ps(f1[(i + 5) * n + k + 4]);
                ymm13 = _mm256_set1_ps(f1[(i + 5) * n + k + 5]);
                ymm14 = _mm256_set1_ps(f1[(i + 5) * n + k + 6]);
                ymm15 = _mm256_set1_ps(f1[(i + 5) * n + k + 7]);

                // multiply
                ymm8 = _mm256_mul_ps(ymm8, ymm0); // row 1, 2
                ymm9 = _mm256_mul_ps(ymm9, ymm1);
                ymm8 = _mm256_add_ps(ymm8, ymm9);

                ymm10 = _mm256_mul_ps(ymm10, ymm2); // row 3, 4
                ymm11 = _mm256_mul_ps(ymm11, ymm3);
                ymm10 = _mm256_add_ps(ymm10, ymm11);

                ymm12 = _mm256_mul_ps(ymm12, ymm4); // row 5, 6
                ymm13 = _mm256_mul_ps(ymm13, ymm5);
                ymm12 = _mm256_add_ps(ymm12, ymm13);

                ymm14 = _mm256_mul_ps(ymm14, ymm6); // row 7, 8
                ymm15 = _mm256_mul_ps(ymm15, ymm7);
                ymm14 = _mm256_add_ps(ymm14, ymm15);

                ymm8 = _mm256_add_ps(ymm8, ymm10); // sum
                ymm12 = _mm256_add_ps(ymm12, ymm14);
                ymm8 = _mm256_add_ps(ymm8, ymm12);

                // save current result
                ymm21 = _mm256_add_ps(ymm21, ymm8);

                // ---------------------------------------------------------- //
                // broadcast each elements from source 1
                ymm8 = _mm256_set1_ps(f1[(i + 6) * n + k + 0]);
                ymm9 = _mm256_set1_ps(f1[(i + 6) * n + k + 1]);
                ymm10 = _mm256_set1_ps(f1[(i + 6) * n + k + 2]);
                ymm11 = _mm256_set1_ps(f1[(i + 6) * n + k + 3]);
                ymm12 = _mm256_set1_ps(f1[(i + 6) * n + k + 4]);
                ymm13 = _mm256_set1_ps(f1[(i + 6) * n + k + 5]);
                ymm14 = _mm256_set1_ps(f1[(i + 6) * n + k + 6]);
                ymm15 = _mm256_set1_ps(f1[(i + 6) * n + k + 7]);

                // multiply
                ymm8 = _mm256_mul_ps(ymm8, ymm0); // row 1, 2
                ymm9 = _mm256_mul_ps(ymm9, ymm1);
                ymm8 = _mm256_add_ps(ymm8, ymm9);

                ymm10 = _mm256_mul_ps(ymm10, ymm2); // row 3, 4
                ymm11 = _mm256_mul_ps(ymm11, ymm3);
                ymm10 = _mm256_add_ps(ymm10, ymm11);

                ymm12 = _mm256_mul_ps(ymm12, ymm4); // row 5, 6
                ymm13 = _mm256_mul_ps(ymm13, ymm5);
                ymm12 = _mm256_add_ps(ymm12, ymm13);

                ymm14 = _mm256_mul_ps(ymm14, ymm6); // row 7, 8
                ymm15 = _mm256_mul_ps(ymm15, ymm7);
                ymm14 = _mm256_add_ps(ymm14, ymm15);

                ymm8 = _mm256_add_ps(ymm8, ymm10); // sum
                ymm12 = _mm256_add_ps(ymm12, ymm14);
                ymm8 = _mm256_add_ps(ymm8, ymm12);

                // save current result
                ymm22 = _mm256_add_ps(ymm22, ymm8);

                // ---------------------------------------------------------- //
                // broadcast each elements from source 1
                ymm8 = _mm256_set1_ps(f1[(i + 7) * n + k + 0]);
                ymm9 = _mm256_set1_ps(f1[(i + 7) * n + k + 1]);
                ymm10 = _mm256_set1_ps(f1[(i + 7) * n + k + 2]);
                ymm11 = _mm256_set1_ps(f1[(i + 7) * n + k + 3]);
                ymm12 = _mm256_set1_ps(f1[(i + 7) * n + k + 4]);
                ymm13 = _mm256_set1_ps(f1[(i + 7) * n + k + 5]);
                ymm14 = _mm256_set1_ps(f1[(i + 7) * n + k + 6]);
                ymm15 = _mm256_set1_ps(f1[(i + 7) * n + k + 7]);

                // multiply
                ymm8 = _mm256_mul_ps(ymm8, ymm0); // row 1, 2
                ymm9 = _mm256_mul_ps(ymm9, ymm1);
                ymm8 = _mm256_add_ps(ymm8, ymm9);

                ymm10 = _mm256_mul_ps(ymm10, ymm2); // row 3, 4
                ymm11 = _mm256_mul_ps(ymm11, ymm3);
                ymm10 = _mm256_add_ps(ymm10, ymm11);

                ymm12 = _mm256_mul_ps(ymm12, ymm4); // row 5, 6
                ymm13 = _mm256_mul_ps(ymm13, ymm5);
                ymm12 = _mm256_add_ps(ymm12, ymm13);

                ymm14 = _mm256_mul_ps(ymm14, ymm6); // row 7, 8
                ymm15 = _mm256_mul_ps(ymm15, ymm7);
                ymm14 = _mm256_add_ps(ymm14, ymm15);

                ymm8 = _mm256_add_ps(ymm8, ymm10); // sum
                ymm12 = _mm256_add_ps(ymm12, ymm14);
                ymm8 = _mm256_add_ps(ymm8, ymm12);

                // save current result
                ymm23 = _mm256_add_ps(ymm23, ymm8);
            }

            _mm256_store_ps((__m256 *)(f3 + (i + 0) * n + j), ymm16);
            _mm256_store_ps((__m256 *)(f3 + (i + 1) * n + j), ymm17);
            _mm256_store_ps((__m256 *)(f3 + (i + 2) * n + j), ymm18);
            _mm256_store_ps((__m256 *)(f3 + (i + 3) * n + j), ymm19);
            _mm256_store_ps((__m256 *)(f3 + (i + 4) * n + j), ymm20);
            _mm256_store_ps((__m256 *)(f3 + (i + 5) * n + j), ymm21);
            _mm256_store_ps((__m256 *)(f3 + (i + 6) * n + j), ymm22);
            _mm256_store_ps((__m256 *)(f3 + (i + 7) * n + j), ymm23);
        }
    }
    memcpy(dst->data,f3,sizeof(float)*n*n);
}